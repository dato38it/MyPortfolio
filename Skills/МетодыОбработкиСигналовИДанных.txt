Task:
Корреляционный анализ. Корреляционная и автокорреляционная функции
Decision:
Корреляционный анализ — метод обработки статистических данных, с помощью которого измеряется теснота связи между двумя или более переменными. Корреляционный анализ тесно связан с регрессионным анализом (также часто встречается термин «корреляционно-регрессионный анализ», который является более общим статистическим понятием), с его помощью определяют необходимость включения тех или иных факторов в уравнение множественной регрессии, а также оценивают полученное уравнение регрессии на соответствие выявленным связям (используя коэффициент детерминации).
Применение возможно при наличии достаточного количества наблюдений для изучения. На практике считается, что число наблюдений должно не менее чем в 5-6 раз превышать число факторов (также встречается рекомендация использовать пропорцию, не менее чем в 10 раз превышающую количество факторов). В случае если число наблюдений превышает количество факторов в десятки раз, в действие вступает закон больших чисел, который обеспечивает взаимопогашение случайных колебаний.
Необходимо, чтобы совокупность значений всех факторных и результативного признаков подчинялась многомерному нормальному распределению. В случае если объём совокупности недостаточен для проведения формального тестирования на нормальность распределения, то закон распределения определяется визуально на основе корреляционного поля. Если в расположении точек на этом поле наблюдается линейная тенденция, то можно предположить, что совокупность исходных данных подчиняется нормальному закону распределенияю
Исходная совокупность значений должна быть качественно однородной.
Сам по себе факт корреляционной зависимости не даёт основания утверждать, что одна из переменных предшествует или является причиной изменений, или то, что переменные вообще причинно связаны между собой, а не наблюдается действие третьего фактора.
Данный метод обработки статистических данных весьма популярен в экономике, астрофизике и социальных науках (в частности в психологии и социологии), хотя сфера применения коэффициентов корреляции обширна: контроль качества промышленной продукции, металловедение, агрохимия, гидробиология, биометрия и прочие. В различных прикладных отраслях приняты разные границы интервалов для оценки тесноты и значимости связи.
Популярность метода обусловлена двумя моментами: коэффициенты корреляции относительно просты в подсчете, их применение не требует специальной математической подготовки. В сочетании с простотой интерпретации, простота применения коэффициента привела к его широкому распространению в сфере анализа статистических данных.
Автокорреляционная функция — зависимость взаимосвязи между функцией (сигналом) и её сдвинутой копией от величины временного сдвига.
Для детерминированных сигналов автокорреляционная функция (АКФ) сигнала f(t) определяется интегралом:
Ψ(τ)=∫f(t)*(f∗)*(t−τ)dt
и показывает связь сигнала (функции f(t) с копией самого себя, смещённого на величину τ. Звёздочка означает комплексное сопряжение.
Для случайных процессов АКФ случайной функции X(t) имеет вид:
K(τ)=E{X(t)*(X∗)*(t−τ)},
где E {} — математическое ожидание, звёздочка означает комплексное сопряжение.
Если исходная функция строго периодическая, то на графике автокорреляционной функции тоже будет строго периодическая функция. Таким образом, из этого графика можно судить о периодичности исходной функции, а, следовательно, и о её частотных характеристиках. Автокорреляционная функция применяется для анализа сложных колебаний, например, электроэнцефалограммы человека.
Зависящая от времени корреляция двух случайных функций X(t) и Y(t)определяется как:
C(t, t′)=⟨X(t)*Y(t′)⟩
где угловые скобки обозначают процедуру усреднения.
Если корреляционная функция вычисляется для одного и того же процесса, она называется автокорреляционной:
Cauto(t,t′)=⟨X(t)*X(t′)⟩
Аналогично можно вычислить корреляционную функцию для процессов, происходящих в разных точках пространства в различные моменты времени:
C(t,r,t′,r′)=⟨X(t,r)*Y(t′,r′)⟩
Корреляционные функции широко используются в статистической физике и других дисциплинах, изучающих случайные (стохастические) процессы.
В статистической физике корреляционная функция описывает, как микроскопические переменные (например, скорости движения атомов) связаны в различных точках пространства в различные моменты времени. Наиболее общее определение имеет следующий вид:
G(r,R,t,τ)=⟨f1(R,t)*f2(R+r,t+τ)⟩
где f1,f2 - функции, корреляции которых мы хотим изучить, угловые скобки означают усреднение по статистическому ансамблю (например, по каноническому).
Если мы интересуемся тем, скореллировано ли меняются микроскопические переменные в один и тот же момент времени в различных точках пространства, мы можем рассматривать функции f1, f2 в один и тот же момент времени, тогда их корреляционная функция запишется в виде:
G(r,R,t)=⟨f1(R,t)f2(R+r,t)⟩
такая корреляционная функция называется одновременной.
Аналогично можно ввести одновременную корреляционную функцию для случая, когда функций f1, f2 не две, а s штук:
G^(s)(r1,...,rn)=⟨f1(r1,t) ... fs(rn,t)⟩
Иногда требуется рассмотреть временную эволюцию микроскопических переменных. Для этого используется пространственная корреляционная функция:
G(R,t,τ)=⟨f1(R,t)f2(R,t+τ)⟩
При этом важно понимать, что несмотря на то, что в равновесии некоторые макроскопические переменные не зависят от времени, микроскопические переменные (такие, как, например, вектор скорости частицы) могут зависеть от времени и поэтому подобные корреляционные функции, являющиеся по сути макроскопическими величинами, тоже могут зависеть от времени. 
Task:
Дискретизация сигналов. Ошибка квантования. Теорема Котельникова. Дискретизация и наложение спектров.
Decision:
Дискретизацией называется замена непрерывного сигнала дискретными отсчетными значениями (отсчетами), взятыми через определенный интервал времени – интервал дискретизации TД.
Дискретный сигнал x (t) Д с математической точки зрения можно рассматривать как результат перемножения функций x(t) и u(t).
Операция квантования сводится к тому, что всем отсчетам входного сигнала x, попавшим в некоторый интервал, приписывается одно и то же значение x ,
выражаемое двоичной кодовой комбинацией. Если кодовая комбинация содержит r разрядов, то число дискретных уровней
выходного сигнала квантователяравно 2^r .
Для взаимно однозначного соответствия весь диапазон изменения входного сигнала
X=xmax–xmin
должен быть разбит на такое же количество уровней.
Величина интервала разбиения - шаг квантования - представляет собой значение аналоговой величины, на которую отличаются уровни входного сигнала,
представленные двумя соседними кодовыми комбинациями.
При наиболее распространенном равномерном квантовании шаг квантования равен
Δ=X/(2^r)
Характеристикой квантования называется зависимость квантованного значения xi от значения непрерывной величины x.
Типичная характеристика квантователяс постоянном шагом квантования:
Временная последовательность ошибок квантования случайного сигнала представляет собой случайный процесс с равномерным законом распределения.
Этот случайный процесс называют шумом квантования. Абсолютное значение ошибки квантования не превышает Δ/2.
Фундаментальной основой теории обработки сигналов служит теорема Котельникова (теорема Найквиста, теорема отсчетов), которая доказывает, что если fm – самая высокая частота в спектре функции x(t), то функция полностью определяется последовательностью своих значений, если выборка осуществляется с частотой не меньшей, чем 2*fm.
Эффекты частотной неоднозначности при неправильном выборе частоты дискретизации.
В восстановленном сигнале будут отсутствовать искажения, если:
АЧХ фильтра равномерна в интервале частот от F1 до Fmax,
ФЧХ линейна в том же диапазоне частот,
коэффициент передачи равен нулю на частотах F >= FД - Fmax
Реализовать такой фильтр можно только при условии FД - Fmax >= Fmax
Из приведенного неравенства вытекает известное соотношение Котельникова, позволяющее выбрать частоту дискретизации FД >= 2 Fmax
Если это условие не выполняется, то возникает наложениеспектров.
Эффект наложения спектров иллюстрируется рисунком выше. Из него видно, что в полосу пропускания фильтра неизбежно попадает спектральная составляющая, которой нет в спектре исходного аналогового сигнала. Это вызывает искажение восстановленного сигнала
Task:
Спектральное представление сигналов. Дискретное и непрерывное преобразование Фурье
Decision:
Любой сигнал можно разложить на составляющие. Такое разложение сигнала называется спектральным. При этом сигнал можно представить в виде графика зависимости параметров сигнала от частоты, такая диаграмма называется спектральной или спектром сигнала.
Спектр сигнала — это совокупность простых составляющих сигнала с определенными амплитудами, частотами и начальными фазами.
Между спектром сигнала и его формой существует жесткая взаимосвязь: изменение формы сигнала приводит к изменению его спектра и наоборот, любое изменение спектра сигнала приводит к изменению его формы. Это важно запомнить, поскольку при передаче сигналов в системе передачи, они подвергаются преобразованиям, а значит, происходит преобразование их спектров.
Различают два вида спектральных диаграмм:
спектральная диаграмма амплитуд;
спектральная диаграмма фаз.
В спектральной диаграмме амплитуд — отображаются все составляющие со своими амплитудами и частотами.
В спектральной диаграмме фаз — отображаются все составляющие со своими начальными фазами и частотами.
Любой сигнал имеет одну спектральную диаграмму амплитуд и одну спектральную диаграмму фаз, в составе которых может содержаться множество составляющих.
Не зависимо от того, какой спектр (амплитуд или фаз), он изображается в виде множества линий — составляющих. В спектре амплитуд высота спектральной линии равна амплитуде составляющей сигнала, а в спектре фаз — начальной фазе составляющей. Причем: в спектре амплитуд все составляющие имеют положительные значения, а в спектре фаз как положительные, так и отрицательные. Если амплитуда спектральной составляющей имеет отрицательный знак, то в спектре амплитуд она берется по модулю, а в спектре фаз знак составляющей изменяется на противоположный.
Непрерывное преобразование само фактически является обобщением более ранней идеи рядов Фурье, которые определены для 2 π {\displaystyle 2\pi } 2\pi -периодических функций и представляют собой разложение таких функций в (бесконечную) линейную комбинацию гармонических колебаний с целыми частотами:
f(x)= Σ(fn*e^(i*n*x)
Разложение в ряд Фурье применимо также к функциям, заданным на ограниченных промежутках, поскольку такие функции могут быть периодически продолжены на всю прямую.
Ряд Фурье является частным случаем преобразования Фурье, если последнее понимать в смысле обобщённых функций. Для любой 2*π-периодической функции имеем
f(ω)=sqrt(2*π)Σ(fn*δ*(ω−n))
Иными словами, преобразование Фурье периодической функции представляет собой сумму точечных нагрузок в целых точках и равно нулю вне их.
Дискретное преобразование Фурье - преобразование конечных последовательностей (комплексных) чисел, которое, как и в непрерывном случае, превращает свёртку в поточечное умножение. Используется в цифровой обработке сигналов и в других ситуациях, где необходимо быстро выполнять свёртку, например, при умножении больших чисел.
Пусть x0, x1, … , xn−1 - последовательность комплексных чисел. Рассмотрим многочлен f(t)=x0+x1*t+x2*t^2+...+(xn-1)*t^(n-1). Выберем какие-нибудь n точек на комплексной плоскости z0, z1, ... , zn-1. Теперь многочлену f(t) мы можем сопоставить новый набор из n чисел: f0:=f(z0), f1:=f(z1), ..., (fn-1):=f(zn-1). Заметим, что это преобразование обратимо: для любого набора чисел f0, f1, ...,fn−1 существует единственный многочлен f(t) степени не выше n-1 с такими значениями в z0, ..., zn-1 соответственно.
Набор {fk} и называется дискретным преобразованием Фурье исходного набора {xk}. В качестве точек zk обычно выбирают корни n-й степени из единицы:
zk=e^(2*πi*k/n).
Такой выбор продиктован тем, что в этом случае обратное преобразование принимает простую форму, а также тем, что вычисление преобразования Фурье может быть выполнено особенно быстро. Так, в то время как вычисление свёртки двух последовательностей длины n напрямую требует порядка n^2 операций, переход к их преобразованию Фурье и обратно по быстрому алгоритму может быть выполнен за O(n*logn) операций. Для преобразований Фурье свёртке соответствует покомпонентное умножение, которое требует лишь порядка n операций.
Task:
Среднее и среднеквадратическое отклонение. Распределение Гаусса. Проверка статистических гипотез.
Decision:
Среднеквадратическое отклонение равно квадратному корню из дисперсии: σ=sqrt(D). При определении среднего квадратического отклонения при достаточно большом объеме изучаемой совокупности (n > 30) применяются формулы:
σ=sqrt(Σ((х1-x)^2)/n) - среднее квадратическое отклонение простое (или невзвешенное);
σ=sqrt(Σ((х1-x)^2*fi)/Σfi) - среднее квадратическое отклонение взвешенное, где: xi – значения изучаемого признака (варианты); n – объем статистической совокупности; x – средняя арифметическая величина.
Среднее квадратическое отклонение характеризует разброс значений относительно среднего (математического ожидания). Обозначается как σ(x) или s(x).
Свойства среднего квадратическоо отклонения:
σ(const)=0
σ(x)≥0
σ(k*x)=k*σ(x)
Среднее квадратическое отклонение суммы или разности двух независимых случайных величин равна квадратному корню от суммы квадратов квадратических отклонений этих величин.
σ(X1+X2+...+Xn)=sqrt((σ^2)*X1+(σ^2)*X2+...+(σ^2)*Xn)
Рассчитать среднеквадратическое отклонение можно разными калькуляторами, в зависимости от исходных данных. Ниже представлены наиболее распространенные из них.
Среднее квадратическое отклонение в рядах распределения:
Равномерное распределение. Дисперсия: D[X]=((b-a)^2)/12. Среднеквадратическое отклонение: σ=sqrt(D)
Нормальное распределение / Распределение Гаусса. Дисперсия: D[X] = σ^2. σ^2=Σ((х1-x)^2*ni)/Σni. Среднеквадратическое отклонение: σ=sqrt(D)
Показательное распределение. Дисперсия: D[X] = 1/(λ^2). Среднеквадратическое отклонение: σ=sqrt(D)
Распределение Пуассона. Дисперсия: D[X]=Σ((х1-λ)^2*ni)/Σni. Среднеквадратическое отклонение: σ=sqrt(D)
Биномиальное распределение. Дисперсия: D[X]=∑(xi^2)*Pi-M[x]^2. Среднеквадратическое отклонение: σ=sqrt(D)
В современном мире мы обладаем все большим и большим объемом данных о событиях, происходящих вокруг. Зачастую у нас появляются вопросы, на которые хотелось бы быстро ответить на основе имеющейся информации, для этого как нельзя лучше подходит процесс, связанный с проверкой статистических гипотез. Однако, многие считают, что это занятие подразумевает под собой большое число вычислений и в принципе довольно сложно для понимания. На самом деле, алгоритм проверки гипотез достаточно прост, а для осуществления расчетов с каждым годом появляется все больше и больше готовых инструментальных средств, не требующих от человека глубоких познаний в области. Далее я попытаюсь показать, что мало того, что процесс проверки гипотез может быть полезным, так и осуществляется достаточно быстро и без серьезных усилий.
Статистическая гипотеза - это предположение о каких-либо характеристиках случайной величины. Например: существенно ли изменение числа AI-стартапов в Европе в два разных года и т. д.
Проверка статистических гипотез является важнейшим классом задач математической статистики. С помощью данного инструмента можно подтвердить или отвергнуть предположение о свойствах случайной величины путем применения методов статистического анализа для элементов выборки. Если в предыдущем предложении какие-либо термины являются не совсем понятными, ниже можно найти пояснение на простом языке.
Случайная величина - это величина, которая в зависимости от той или иной ситуации принимает конкретные значения с определенными вероятностями. Примеры: отметка на экзамене; результат игры в кости; количество AI-стартапов по странам Европы. В общем, почти все что угодно!
Генеральная совокупность - совокупность всех объектов для анализа. Например: все AI-стартапы в Европе в 2019-м году.
Выборка - часть данных из генеральной совокупности. Например: официально зарегистрированные AI-стартапы в некоторых странах Европы в 2019-м году.
Статистический анализ - использование различных методов для того, чтобы определить свойства генеральной совокупности по выборке.
Для проверки статистических гипотез зачастую применяются статистические тесты, о которых будет рассказано далее.
В обобщенном виде алгоритм выглядит таким образом:
Формулировка основной (H0) и альтернативной (H1) гипотез
Выбор уровня значимости
Выбор статистического критерия
Определения правила принятия решения 
Итоговое принятие решения на основе исходной выборки данных
Данные шаги являются унифицированными и схему можно использовать почти во всех случаях. Далее подробнее рассмотрим пример работы данного алгоритма на конкретных данных.
Source:
https://math.semestr.ru/group/standard-deviation.php
https://habr.com/ru/post/558836/
https://conture.by/post/592
https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B5%D0%BE%D0%B1%D1%80%D0%B0%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%A4%D1%83%D1%80%D1%8C%D0%B5#%D0%A0%D1%8F%D0%B4%D1%8B_%D0%A4%D1%83%D1%80%D1%8C%D0%B5
https://fks.mirea.ru/wp-content/uploads/Items/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0/9_Auto_Phy_9-quantdiscr_18.pdf
https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%80%D1%80%D0%B5%D0%BB%D1%8F%D1%86%D0%B8%D1%8F#%D0%9A%D0%BE%D1%80%D1%80%D0%B5%D0%BB%D1%8F%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7
https://ru.wikipedia.org/wiki/%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D1%80%D1%80%D0%B5%D0%BB%D1%8F%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F
https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%80%D1%80%D0%B5%D0%BB%D1%8F%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F